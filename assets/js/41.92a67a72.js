(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{446:function(a,t,s){"use strict";s.r(t);var n=s(2),r=Object(n.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"什么是ollama"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#什么是ollama"}},[a._v("#")]),a._v(" 什么是ollama")]),a._v(" "),t("p",[a._v("可以使用ollama在本地快速部署一个大模型，无需任何代码，并且与LangChain, AutoGen,etc完美集成。\n在详细介绍使用ollama之前，我们先回顾一下为什么需要本地部署LLM。")]),a._v(" "),t("h2",{attrs:{id:"本地部署llm为什么重要"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#本地部署llm为什么重要"}},[a._v("#")]),a._v(" 本地部署LLM为什么重要？")]),a._v(" "),t("p",[a._v("使用本地部署的LLM有以下好处：")]),a._v(" "),t("ul",[t("li",[a._v("隐私保护：当使用公共API或chatgpt时，你的使用记录将会被记录下来。")]),a._v(" "),t("li",[a._v("费用：chatgpt等模型的借口需要付费使用。")]),a._v(" "),t("li",[a._v("灵活使用：基于本地构建的LLM借口灵活构建应用。\nOllama就是一个帮助你本地快速构建LLM的软件！")])]),a._v(" "),t("h2",{attrs:{id:"ollama"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#ollama"}},[a._v("#")]),a._v(" Ollama")]),a._v(" "),t("p",[a._v("这是Ollama软件官方支持的一键加载的大模型：\nhttps://ollama.com/library\n其中包括我们常用的：llama、mistral、codegemma等......甚至支持多模态大模型Llava、BakLlava等文生图或图生文。\n具体使用步骤如下：")]),a._v(" "),t("ul",[t("li",[a._v("https://ollama.com/打开官网页面，并点击下载对应系统的ollama")]),a._v(" "),t("li",[a._v("执行ollama run llama2，等待对应的模型参数下载完成后，就可以询问问题了。具体版本对应的命令请在官网查找https://ollama.com/library")])]),a._v(" "),t("h2",{attrs:{id:"其他"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[a._v("#")]),a._v(" 其他")]),a._v(" "),t("p",[a._v("当然ollama不仅对非程序员人员非常友好，对程序员也有便捷的用法，ollama和python、langchain天然集成，非常好用。")]),a._v(" "),t("h3",{attrs:{id:"python-with-ollama"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#python-with-ollama"}},[a._v("#")]),a._v(" python with ollama")]),a._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" ollama\nollama"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("generate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("model"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("'llama2'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(",")]),a._v("prompt"),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("'为什么天空时蓝色的？'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("python中只需要两行代码就可以加载llama2-7b模型进行推理了！")]),a._v(" "),t("h3",{attrs:{id:"langchain-with-ollama"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#langchain-with-ollama"}},[a._v("#")]),a._v(" langchain with ollama")]),a._v(" "),t("div",{staticClass:"language-python extra-class"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("from")]),a._v(" langchain_community"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("chat_models "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" ChatOllama\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("from")]),a._v(" langchain_core"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("output_parsers "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" StrOutputParser\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("from")]),a._v(" langchain_core"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("prompts "),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("import")]),a._v(" ChatPromptTemplate\n\nllm "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" ChatOllama"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("model "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[a._v("'llama2'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\nprompt "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" ChatPromptTemplate"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("from_template"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"Explain {topic} in short bulllet points"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n\nchain "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("=")]),a._v(" prompt "),t("span",{pre:!0,attrs:{class:"token operator"}},[a._v("|")]),a._v(" llm\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[a._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),a._v("chain"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(".")]),a._v("invoke"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"topic"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(":")]),t("span",{pre:!0,attrs:{class:"token string"}},[a._v('"River rafting"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[a._v(")")]),a._v("\n")])])]),t("p",[a._v("不仅如此支持多智能体的langgraph、autogen、crewai等都支持。")]),a._v(" "),t("h2",{attrs:{id:"总结"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[a._v("#")]),a._v(" 总结")]),a._v(" "),t("p",[a._v("总而言之，ollama是一个便捷的工具，跳过下载模型和编写推理代码的部分，直接一步就可以拉起模型")])])}),[],!1,null,null,null);t.default=r.exports}}]);