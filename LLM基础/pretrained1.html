<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>å¤§æ¨¡å‹çš„lossæ€ä¹ˆè®¡ç®—ï¼Ÿ | LLMå­¦ä¹ è®°å½•</title>
    <meta name="generator" content="VuePress 1.9.10">
    
    <meta name="description" content="è®°å½•å¤§æ¨¡å‹å­¦ä¹ ç¬”è®°ï½">
    
    <link rel="preload" href="./assets/css/0.styles.9d97ee6f.css" as="style"><link rel="preload" href="./assets/js/app.427a5c72.js" as="script"><link rel="preload" href="./assets/js/7.7c04b33d.js" as="script"><link rel="preload" href="./assets/js/2.fc98b07a.js" as="script"><link rel="preload" href="./assets/js/1.227b7bc4.js" as="script"><link rel="preload" href="./assets/js/39.01cf69c5.js" as="script"><link rel="prefetch" href="./assets/js/10.dfb0299a.js"><link rel="prefetch" href="./assets/js/11.479e3941.js"><link rel="prefetch" href="./assets/js/14.c5aa2906.js"><link rel="prefetch" href="./assets/js/15.4691ff28.js"><link rel="prefetch" href="./assets/js/16.520dd9c6.js"><link rel="prefetch" href="./assets/js/17.85dc844f.js"><link rel="prefetch" href="./assets/js/18.060d220d.js"><link rel="prefetch" href="./assets/js/19.d0231ffe.js"><link rel="prefetch" href="./assets/js/20.02ef4689.js"><link rel="prefetch" href="./assets/js/21.4913a81b.js"><link rel="prefetch" href="./assets/js/22.ec2bffa8.js"><link rel="prefetch" href="./assets/js/23.360d4cb3.js"><link rel="prefetch" href="./assets/js/24.8df16635.js"><link rel="prefetch" href="./assets/js/25.bda1b3e1.js"><link rel="prefetch" href="./assets/js/26.06377f0d.js"><link rel="prefetch" href="./assets/js/27.86112ea9.js"><link rel="prefetch" href="./assets/js/28.be8ca15b.js"><link rel="prefetch" href="./assets/js/29.98f0eb72.js"><link rel="prefetch" href="./assets/js/3.be741a74.js"><link rel="prefetch" href="./assets/js/30.4c7947d3.js"><link rel="prefetch" href="./assets/js/31.8e410bcb.js"><link rel="prefetch" href="./assets/js/32.bac8f00d.js"><link rel="prefetch" href="./assets/js/33.cb9d2429.js"><link rel="prefetch" href="./assets/js/34.380ce34c.js"><link rel="prefetch" href="./assets/js/35.b5fcd8bd.js"><link rel="prefetch" href="./assets/js/36.34421d06.js"><link rel="prefetch" href="./assets/js/37.d64318d3.js"><link rel="prefetch" href="./assets/js/38.54e3932b.js"><link rel="prefetch" href="./assets/js/4.38e5a85b.js"><link rel="prefetch" href="./assets/js/40.35b9d7c3.js"><link rel="prefetch" href="./assets/js/41.92a67a72.js"><link rel="prefetch" href="./assets/js/42.3b5222cb.js"><link rel="prefetch" href="./assets/js/43.7bd6dc89.js"><link rel="prefetch" href="./assets/js/5.1a3770ee.js"><link rel="prefetch" href="./assets/js/6.3951b5be.js"><link rel="prefetch" href="./assets/js/8.617b6635.js"><link rel="prefetch" href="./assets/js/9.def61537.js"><link rel="prefetch" href="./assets/js/vendors~docsearch.86fb114e.js">
    <link rel="stylesheet" href="./assets/css/0.styles.9d97ee6f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>LLMå­¦ä¹ è®°å½•</h3> <p class="description" data-v-59e6cb88>è®°å½•å¤§æ¨¡å‹å­¦ä¹ ç¬”è®°ï½</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
        Â Â 
        <!---->
        2024
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/./" class="home-link router-link-active"><!----> <span class="site-name">LLMå­¦ä¹ è®°å½•</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/./" class="nav-link"><i class="undefined"></i>
  é¦–é¡µ
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      æ¨é”æ‹©çš„ LLM åšå®¢
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/YangSuoze" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><!----> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>6</h3> <h6 data-v-1fad0c41>Articles</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>0</h3> <h6 data-v-1fad0c41>Tags</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/./" class="nav-link"><i class="undefined"></i>
  é¦–é¡µ
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      æ¨é”æ‹©çš„ LLM åšå®¢
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/YangSuoze" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/./" class="sidebar-heading clickable router-link-active"><span>æ¬¢è¿å­¦ä¹ </span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/./" aria-current="page" class="sidebar-link">Hello</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/./LLMåŸºç¡€/transformer" class="sidebar-heading clickable open"><span>åŸºç¡€å­¦ä¹ </span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/./LLMåŸºç¡€/transformer.html" class="sidebar-link">transformer</a></li><li><a href="/./LLMåŸºç¡€/deepspeed.html" class="sidebar-link">deepspeed</a></li><li><a href="/./LLMåŸºç¡€/pretrained1.html" class="active sidebar-link">å¤§æ¨¡å‹çš„lossæ€ä¹ˆè®¡ç®—ï¼Ÿ</a></li><li><a href="/./LLMåŸºç¡€/ä½¿ç”¨ollamaå¿«é€Ÿéƒ¨ç½²LLM.html" class="sidebar-link">ä½¿ç”¨ollamaå¿«é€Ÿéƒ¨ç½²LLM</a></li><li><a href="/./LLMåŸºç¡€/å¤šæ™ºèƒ½ä½“ç¼–æ’.html" class="sidebar-link">å¤šæ™ºèƒ½ä½“ç¼–æ’</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>å¤§æ¨¡å‹çš„lossæ€ä¹ˆè®¡ç®—ï¼Ÿ</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
        Â Â 
        <!---->
        2024
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page" style="padding-right:0;"><section style="display:;"><div class="page-title"><h1 class="title">å¤§æ¨¡å‹çš„lossæ€ä¹ˆè®¡ç®—ï¼Ÿ</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>Jessica</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>4/22/2024</span></i> <!----> <!----></div></div> <div class="theme-reco-content content__default"><h2 id="å¤§æ¨¡å‹é¢„è®­ç»ƒçš„å‡ ç§æ–¹å¼"><a href="#å¤§æ¨¡å‹é¢„è®­ç»ƒçš„å‡ ç§æ–¹å¼" class="header-anchor">#</a> å¤§æ¨¡å‹é¢„è®­ç»ƒçš„å‡ ç§æ–¹å¼</h2> <p>å¸¸ç”¨ çš„é¢„è®­ç»ƒä»»åŠ¡ä¸»è¦åˆ†ä¸ºä¸‰ç±»ï¼ŒåŒ…æ‹¬<strong>è¯­è¨€å»ºæ¨¡(Language Modeling, LM)ã€å»å™ªè‡ªç¼– ç (Denoising Autoencoding, DAE)ä»¥åŠæ··åˆå»å™ªå™¨(Mixture-of-Denoisers, MoD)</strong>ã€‚</p> <h2 id="è¯­è¨€å»ºæ¨¡"><a href="#è¯­è¨€å»ºæ¨¡" class="header-anchor">#</a> è¯­è¨€å»ºæ¨¡</h2> <ul><li>åœ¨å‰ç¼€è§£ç å™¨ä¸­ï¼Œä»…åç¼€ä¸­çš„è¯å…ƒæŸå¤±ä¼šè¢«è®¡å…¥æ€»æŸå¤±ã€‚</li> <li>è¯­è¨€å»ºæ¨¡çš„å¦ä¸€ä¸ªé‡è¦å˜ç§æ˜¯ä¸­é—´å¡«å……ä»»åŠ¡ï¼šä¸€ä¸ªè¾“å…¥ åºåˆ— ğ’– è¢«åˆ’åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†:å‰ç¼€ ğ’–prefixã€ä¸­é—´éƒ¨åˆ† ğ’–middle å’Œåç¼€ ğ’–suffixã€‚éšåï¼Œä¸­ é—´éƒ¨åˆ†è¢«ç§»è‡³åºåˆ—æœ«å°¾ã€‚å› æ­¤ï¼Œæ¨¡å‹éœ€è¦è‡ªå›å½’åœ°å¯¹æ–°åºåˆ— ğ’–prefix âŠ• ğ’–suffix âŠ• ğ’–middle è¿›è¡Œé¢„æµ‹ã€‚â€”â€”è¿™ç§æ–¹æ³•ä½¿å¾—æ¨¡å‹å…·å¤‡å¯¹äºæ–‡æœ¬ä¸­é—´éƒ¨åˆ†å†…å®¹çš„æ¢å¤èƒ½åŠ›ã€‚è¿™ ç§é¢„è®­ç»ƒä»»åŠ¡ç»å¸¸è¢«ç”¨äºè®­ç»ƒä»£ç é¢„è®­ç»ƒæ¨¡å‹ï¼Œä»è€Œæå‡æ¨¡å‹åœ¨ä»£ç è¡¥å…¨ç­‰å®é™… åº”ç”¨åœºæ™¯ä¸­çš„è¡¨ç°ã€‚</li> <li>å»å™ªè‡ªç¼–ç ï¼šåŠ å…¥maskå™ªå£°çš„æ¨¡å‹ï¼Œå¦‚bertæ—ï¼Œç›®æ ‡æ˜¯é¢„æµ‹maskå¯¹åº”çš„çœŸå®æ ‡ç­¾</li></ul> <h2 id="how-do-llms-generate-text"><a href="#how-do-llms-generate-text" class="header-anchor">#</a> How do LLMs generate text?</h2> <p><img src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*tx6Dl7z7Cv0vQnvG7KVVIA.png" alt="alt text"></p> <p><code>In general terms, shown in Figure 1, LLMs take in a sequence of tokens as input, pass them through its model layers, and output a sequence of logits. Logits would have the size of its vocabulary. Using a Softmax function, we can convert the logits into multiclass probability. â€œClassâ€ in this case would be tokens or â€œwordsâ€ in the modelâ€™s vocabulary.</code></p> <p><img src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*I4oDEe_29uRnwnha_MQDrw.png" alt="alt text"></p> <p><code>This word probability indicates how likely the model â€œthinksâ€ the word should be generated at that position. A trivial way of generation would be â€œgreedy decodingâ€ where the token with the highest probability is generated.</code></p> <h2 id="how-are-llms-pre-trained-what-is-causal-language-modeling"><a href="#how-are-llms-pre-trained-what-is-causal-language-modeling" class="header-anchor">#</a> How are LLMs pre-trained? What is Causal Language Modeling?</h2> <p>In CLM, the model will be trained to predict the next token or word in a sequence based on preceding tokens. Thus, during CLM, True labels are taken as the input tokens shifted to the left by 1 position.</p> <p><img src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*zyhNiKkp0I4cdSeu-IX95A.png" alt=""></p> <p>For example, if our input text is â€œ&lt;s&gt; I love dogs not catsâ€, our true labels will be â€œI love dogs not catsâ€ which are shifted from the input.</p> <p>Loss is calculated from this comparison of output and true labels. The model will then learn from this loss. Essentially, we are measuring the modelâ€™s ability to predict the next word.</p> <h2 id="loss-visualisation"><a href="#loss-visualisation" class="header-anchor">#</a> Loss Visualisation!</h2> <p>There are many loss functions available but we will discuss the Cross Entropy Loss in this article. As seen in Figure 1, the softmax function will output a multiclass probability vector for each position of the sequence. This probability vector will be used in the calculation of the loss in the following way.</p> <p><img src="https://miro.medium.com/v2/resize:fit:1352/format:webp/1*YWTag9DZv1KERG3bZqA-sA.png" alt="Definition of mean aggregated Cross Entropy"></p> <h3 id="step1"><a href="#step1" class="header-anchor">#</a> Step1</h3> <p><img src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*acIWUIqD0_SXGyZ1weeezg.png" alt="">
The vocab token index of true labels will have to be extracted. As shown in Figure, referencing the Vocab table, the true label at position 0 â€œIâ€ would have an index of 1. True label at position 1 â€œloveâ€ would have an index of 4.</p> <h3 id="step2"><a href="#step2" class="header-anchor">#</a> Step2</h3> <p><img src="https://miro.medium.com/v2/resize:fit:2000/format:webp/1*5BSM35GrOwuYcHitD1NY4g.png" alt=""></p> <h3 id="step3"><a href="#step3" class="header-anchor">#</a> Step3</h3> <p>Once we have the softmax probabilities, we will apply a negative log and aggregate them by taking the mean. From the example in Figure, our Cross Entropy loss will be mean([-log(0.5), -log(0.3),-log(0.33),-log(0.45),-log(0.6)]) = 0.86302.</p> <p>CE loss is measuring if the model gives the true â€œnext wordâ€ a high probability. The lower the loss, the higher the model probability of the true â€œnext wordâ€.</p> <h2 id="how-it-looks-like-in-code"><a href="#how-it-looks-like-in-code" class="header-anchor">#</a> How it looks like in code!</h2> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> transformers
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> CrossEntropyLoss

<span class="token comment"># personal huggingface access token will be needed to use Llama2 models</span>
ACCESS_TOKEN_WRITE <span class="token operator">=</span> <span class="token comment"># hugging face access token</span>
cache_dir_local <span class="token operator">=</span> <span class="token comment"># dir for cache</span>

BASE_MODEL <span class="token operator">=</span> <span class="token string">&quot;meta-llama/Llama-2-7b-hf&quot;</span>
<span class="token comment"># initialise tokenizer</span>
llama2_tokenizer <span class="token operator">=</span> \
AutoTokenizer<span class="token punctuation">.</span>\
from_pretrained<span class="token punctuation">(</span>BASE_MODEL<span class="token punctuation">,</span> 
                padding_side<span class="token operator">=</span><span class="token string">&quot;left&quot;</span><span class="token punctuation">,</span> 
                use_auth_token<span class="token operator">=</span>ACCESS_TOKEN_WRITE<span class="token punctuation">,</span>
               cache_dir<span class="token operator">=</span>cache_dir_local<span class="token punctuation">)</span>

<span class="token comment"># initialise model</span>
llama2_model <span class="token operator">=</span> \
AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    BASE_MODEL<span class="token punctuation">,</span> 
    use_cache<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    device_map<span class="token operator">=</span><span class="token string">&quot;auto&quot;</span><span class="token punctuation">,</span>
    cache_dir<span class="token operator">=</span>cache_dir_local<span class="token punctuation">,</span>
    use_auth_token<span class="token operator">=</span>ACCESS_TOKEN_WRITE<span class="token punctuation">)</span>

<span class="token comment"># example input text</span>
text_input <span class="token operator">=</span> <span class="token string">'I love dogs not cats'</span>
toks <span class="token operator">=</span> llama2_tokenizer<span class="token punctuation">(</span>text_input<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">'pt'</span><span class="token punctuation">)</span>
<span class="token comment"># labels of CLM can be taken as inputs, huggingface will handle the shifting of the labels as mentioned above.</span>
toks<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token operator">=</span> toks<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span>

out <span class="token operator">=</span> llama2_model<span class="token punctuation">(</span><span class="token operator">**</span>toks<span class="token punctuation">,</span> output_hidden_states<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_dict<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(4.6854, grad_fn=&lt;NllLossBackward0&gt;)</span>
</code></pre></div><p>Now letâ€™s try to calculate the loss manually.</p> <div class="language-python extra-class"><pre class="language-python"><code>logits <span class="token operator">=</span> out<span class="token punctuation">[</span><span class="token string">'logits'</span><span class="token punctuation">]</span>
labels <span class="token operator">=</span> toks<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
<span class="token comment"># following model wrapper in huggingface</span>
shift_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
shift_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># flatten batch</span>
shift_logits <span class="token operator">=</span> shift_logits<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32000</span><span class="token punctuation">)</span>
shift_labels <span class="token operator">=</span> shift_labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>shift_labels<span class="token punctuation">)</span>
<span class="token comment"># tensor([  306,  5360, 26361,   451,   274,  1446])</span>
</code></pre></div><p>First, we extract the token indexes of the true labels [ 306, 5360, 26361, 451, 274, 1446].</p> <div class="language-python extra-class"><pre class="language-python"><code>softmax_prob_at_label_tokidx <span class="token operator">=</span> \
torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>shift_logits<span class="token punctuation">)</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>shift_labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> shift_labels<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>softmax_prob_at_label_tokidx<span class="token punctuation">)</span>
<span class="token comment"># tensor([1.0475e-02, 1.5564e-02, 8.7919e-04, 1.5152e-04, 2.8680e-02, 9.9225e-01],</span>
<span class="token comment"># grad_fn=&lt;IndexBackward0&gt;)</span>
</code></pre></div><p>Next, we apply the softmax function to the output logits and take the probability at the true label token index as shown in the comments.</p> <div class="language-python extra-class"><pre class="language-python"><code>loss <span class="token operator">=</span> <span class="token punctuation">(</span>softmax_prob_at_label_tokidx<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
<span class="token comment"># tensor(4.6854, grad_fn=&lt;MeanBackward0&gt;)</span>

<span class="token comment"># double checking with cross entropy function</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>shift_logits<span class="token punctuation">,</span> shift_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(4.6854, grad_fn=&lt;NllLossBackward0&gt;)</span>
</code></pre></div><p>Finally, we apply the negative log and mean aggregation and see that the loss calculated manually is also 4.6854.</p></div></section> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/./LLMåŸºç¡€/deepspeed.html" class="prev">
          deepspeed
        </a></span> <span class="next"><a href="/./LLMåŸºç¡€/ä½¿ç”¨ollamaå¿«é€Ÿéƒ¨ç½²LLM.html">
          ä½¿ç”¨ollamaå¿«é€Ÿéƒ¨ç½²LLM
        </a></span></p></div> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:0;" data-v-b57cc07c data-v-7dd95ae2></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="./assets/js/app.427a5c72.js" defer></script><script src="./assets/js/7.7c04b33d.js" defer></script><script src="./assets/js/2.fc98b07a.js" defer></script><script src="./assets/js/1.227b7bc4.js" defer></script><script src="./assets/js/39.01cf69c5.js" defer></script>
  </body>
</html>
