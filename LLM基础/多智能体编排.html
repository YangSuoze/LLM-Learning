<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>多智能体编排 | LLM学习记录</title>
    <meta name="generator" content="VuePress 1.9.10">
    
    <meta name="description" content="记录大模型学习笔记～">
    
    <link rel="preload" href="./assets/css/0.styles.9d97ee6f.css" as="style"><link rel="preload" href="./assets/js/app.427a5c72.js" as="script"><link rel="preload" href="./assets/js/7.7c04b33d.js" as="script"><link rel="preload" href="./assets/js/2.fc98b07a.js" as="script"><link rel="preload" href="./assets/js/1.227b7bc4.js" as="script"><link rel="preload" href="./assets/js/42.3b5222cb.js" as="script"><link rel="prefetch" href="./assets/js/10.dfb0299a.js"><link rel="prefetch" href="./assets/js/11.479e3941.js"><link rel="prefetch" href="./assets/js/14.c5aa2906.js"><link rel="prefetch" href="./assets/js/15.4691ff28.js"><link rel="prefetch" href="./assets/js/16.520dd9c6.js"><link rel="prefetch" href="./assets/js/17.85dc844f.js"><link rel="prefetch" href="./assets/js/18.060d220d.js"><link rel="prefetch" href="./assets/js/19.d0231ffe.js"><link rel="prefetch" href="./assets/js/20.02ef4689.js"><link rel="prefetch" href="./assets/js/21.4913a81b.js"><link rel="prefetch" href="./assets/js/22.ec2bffa8.js"><link rel="prefetch" href="./assets/js/23.360d4cb3.js"><link rel="prefetch" href="./assets/js/24.8df16635.js"><link rel="prefetch" href="./assets/js/25.bda1b3e1.js"><link rel="prefetch" href="./assets/js/26.06377f0d.js"><link rel="prefetch" href="./assets/js/27.86112ea9.js"><link rel="prefetch" href="./assets/js/28.be8ca15b.js"><link rel="prefetch" href="./assets/js/29.98f0eb72.js"><link rel="prefetch" href="./assets/js/3.be741a74.js"><link rel="prefetch" href="./assets/js/30.4c7947d3.js"><link rel="prefetch" href="./assets/js/31.8e410bcb.js"><link rel="prefetch" href="./assets/js/32.bac8f00d.js"><link rel="prefetch" href="./assets/js/33.cb9d2429.js"><link rel="prefetch" href="./assets/js/34.380ce34c.js"><link rel="prefetch" href="./assets/js/35.b5fcd8bd.js"><link rel="prefetch" href="./assets/js/36.34421d06.js"><link rel="prefetch" href="./assets/js/37.d64318d3.js"><link rel="prefetch" href="./assets/js/38.54e3932b.js"><link rel="prefetch" href="./assets/js/39.01cf69c5.js"><link rel="prefetch" href="./assets/js/4.38e5a85b.js"><link rel="prefetch" href="./assets/js/40.35b9d7c3.js"><link rel="prefetch" href="./assets/js/41.92a67a72.js"><link rel="prefetch" href="./assets/js/43.7bd6dc89.js"><link rel="prefetch" href="./assets/js/5.1a3770ee.js"><link rel="prefetch" href="./assets/js/6.3951b5be.js"><link rel="prefetch" href="./assets/js/8.617b6635.js"><link rel="prefetch" href="./assets/js/9.def61537.js"><link rel="prefetch" href="./assets/js/vendors~docsearch.86fb114e.js">
    <link rel="stylesheet" href="./assets/css/0.styles.9d97ee6f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-7dd95ae2><div data-v-7dd95ae2><div class="password-shadow password-wrapper-out" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>LLM学习记录</h3> <p class="description" data-v-59e6cb88>记录大模型学习笔记～</p> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2024
      </a></span></div></div> <div class="hide" data-v-7dd95ae2><header class="navbar" data-v-7dd95ae2><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/./" class="home-link router-link-active"><!----> <span class="site-name">LLM学习记录</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/./" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      杨锁择的 LLM 博客
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/YangSuoze" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-7dd95ae2></div> <aside class="sidebar" data-v-7dd95ae2><div class="personal-info-wrapper" data-v-1fad0c41 data-v-7dd95ae2><!----> <!----> <div class="num" data-v-1fad0c41><div data-v-1fad0c41><h3 data-v-1fad0c41>6</h3> <h6 data-v-1fad0c41>Articles</h6></div> <div data-v-1fad0c41><h3 data-v-1fad0c41>0</h3> <h6 data-v-1fad0c41>Tags</h6></div></div> <ul class="social-links" data-v-1fad0c41></ul> <hr data-v-1fad0c41></div> <nav class="nav-links"><div class="nav-item"><a href="/./" class="nav-link"><i class="undefined"></i>
  首页
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="undefined"></i>
      杨锁择的 LLM 博客
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/YangSuoze" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="undefined"></i>
  Github
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><a href="/./" class="sidebar-heading clickable router-link-active"><span>欢迎学习</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/./" aria-current="page" class="sidebar-link">Hello</a></li></ul></section></li><li><section class="sidebar-group depth-0"><a href="/./LLM基础/transformer" class="sidebar-heading clickable open"><span>基础学习</span> <!----></a> <ul class="sidebar-links sidebar-group-items"><li><a href="/./LLM基础/transformer.html" class="sidebar-link">transformer</a></li><li><a href="/./LLM基础/deepspeed.html" class="sidebar-link">deepspeed</a></li><li><a href="/./LLM基础/pretrained1.html" class="sidebar-link">大模型的loss怎么计算？</a></li><li><a href="/./LLM基础/使用ollama快速部署LLM.html" class="sidebar-link">使用ollama快速部署LLM</a></li><li><a href="/./LLM基础/多智能体编排.html" class="active sidebar-link">多智能体编排</a></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-59e6cb88 data-v-7dd95ae2><h3 class="title" data-v-59e6cb88>多智能体编排</h3> <!----> <label id="box" class="inputBox" data-v-59e6cb88><input type="password" value="" data-v-59e6cb88> <span data-v-59e6cb88>Konck! Knock!</span> <button data-v-59e6cb88>OK</button></label> <div class="footer" data-v-59e6cb88><span data-v-59e6cb88><i class="iconfont reco-theme" data-v-59e6cb88></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-59e6cb88>vuePress-theme-reco</a></span> <span data-v-59e6cb88><i class="iconfont reco-copyright" data-v-59e6cb88></i> <a data-v-59e6cb88><!---->
          
        <!---->
        2024
      </a></span></div></div> <div data-v-7dd95ae2><div data-v-7dd95ae2><main class="page" style="padding-right:0;"><section style="display:;"><div class="page-title"><h1 class="title">多智能体编排</h1> <div data-v-8a445198><i class="iconfont reco-account" data-v-8a445198><span data-v-8a445198>Jessica</span></i> <i class="iconfont reco-date" data-v-8a445198><span data-v-8a445198>4/23/2024</span></i> <!----> <!----></div></div> <div class="theme-reco-content content__default"><p>多智能体编排即Multi-Agent Orchestration（MAO），当下如Autogen, CrewAI 和 LangGraph均可灵活实现多智能体编排。
本文将主要分为以下几个部分：</p> <ul><li>什么是MAO</li> <li>不同的用例</li> <li>AutoGen用例</li> <li>CrewAI用例</li> <li>LangGraph用例</li></ul> <h2 id="mao"><a href="#mao" class="header-anchor">#</a> MAO</h2> <p><code>Multi-Agent Orchestration (MAO) refers to multi AI agents with different capabilities working together to solve a problem.</code>
主要有以下几个特点：</p> <ul><li>AI-Agent之间可以一步一步的讨论，并实现最终的目标</li> <li>AI-Agent之间以对话形式展开，就像人类一样</li> <li>agent的转换和选择都是由LLM自主进行的</li> <li>用户根据团队需要可以给不同agent分配不同的角色</li></ul> <h2 id="用例"><a href="#用例" class="header-anchor">#</a> 用例</h2> <p><strong>软件开发</strong>：一个软件开发团队合作开发软件
<strong>决策</strong>：举行一个虚拟的圆桌会议，就某一主题进行辩论，让不同的代理Agent扮演不同的角色，做出商业决策。
<strong>Simulations</strong>：An entirely fake scenario with different agent playing different roles.</p> <h2 id="autogen"><a href="#autogen" class="header-anchor">#</a> AutoGen</h2> <p>由微软开发，擅长执行需要生成代码的任务。</p> <ul><li>首先，终端中执行命令：<code>litellm --model huggingface/google/gemma-2b-it</code>，此时模型推理端口将被自动拉起</li> <li>以下是一个快速使用AutoGen的小demo，其中有两个Agent分别是AssistantAgent和UserProxyAgent</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> pprint
<span class="token keyword">from</span> autogen <span class="token keyword">import</span> AssistantAgent<span class="token punctuation">,</span> UserProxyAgent
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'AUTOGEN_USE_DOCKER'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'no'</span>

config_list <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">'model'</span><span class="token punctuation">:</span><span class="token string">'my_local_model'</span><span class="token punctuation">,</span>
        <span class="token string">'url'</span><span class="token punctuation">:</span><span class="token string">'http://0.0.0.0:4000/'</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
llm_config <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'config_list'</span><span class="token punctuation">:</span>config_list<span class="token punctuation">}</span>
assistant <span class="token operator">=</span> AssistantAgent<span class="token punctuation">(</span><span class="token string">'assistant'</span><span class="token punctuation">,</span>llm_config <span class="token operator">=</span> llm_config<span class="token punctuation">)</span>
userproxy <span class="token operator">=</span> UserProxyAgent<span class="token punctuation">(</span><span class="token string">'user_proxy'</span><span class="token punctuation">,</span>is_termination_msg <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
chat_result <span class="token operator">=</span> user_proxy<span class="token punctuation">.</span>initiate_chat<span class="token punctuation">(</span>assistant<span class="token punctuation">,</span> message <span class="token operator">=</span> <span class="token string">'Write a shell script to isplay files.'</span><span class="token punctuation">)</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>chat_result<span class="token punctuation">)</span>
</code></pre></div><ul><li>在群体讨论场景中使用AutoGen</li></ul> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> pprint
<span class="token keyword">import</span> autogen
<span class="token keyword">import</span> os
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'AUTOGEN_USE_DOCKER'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'no'</span>

config_list <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{</span>
        <span class="token string">'model'</span><span class="token punctuation">:</span><span class="token string">'my_local_model'</span><span class="token punctuation">,</span>
        <span class="token string">'base_url'</span><span class="token punctuation">:</span><span class="token string">'http://0.0.0.0:4000/'</span><span class="token punctuation">,</span>
        <span class="token string">'timeout'</span><span class="token punctuation">:</span><span class="token number">100000</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
llm_config <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'config_list'</span><span class="token punctuation">:</span>config_list<span class="token punctuation">,</span><span class="token string">'cache_seed'</span><span class="token punctuation">:</span><span class="token number">42</span><span class="token punctuation">}</span>

<span class="token comment"># 初始化不同的agent角色</span>
user_proxy <span class="token operator">=</span> autogen<span class="token punctuation">.</span>UserProxyAgent<span class="token punctuation">(</span>
    name <span class="token operator">=</span> <span class="token string">'User_proxy'</span><span class="token punctuation">,</span>
    system_message <span class="token operator">=</span> <span class="token string">'A human admin.'</span><span class="token punctuation">,</span>
    code_execution_config <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">'last_n_messages'</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    human_input_mode <span class="token operator">=</span> <span class="token string">'TERMINATE'</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

coder <span class="token operator">=</span> autogen<span class="token punctuation">.</span>AssistantAgent<span class="token punctuation">(</span>
    name <span class="token operator">=</span> <span class="token string">'Coder'</span><span class="token punctuation">,</span>
    llm_config <span class="token operator">=</span> llm_config<span class="token punctuation">,</span>
    system_message <span class="token operator">=</span> <span class="token string">'Understands codes and technialities of any feature evelopment.'</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

pm <span class="token operator">=</span> autogen<span class="token punctuation">.</span>AssistantAgent<span class="token punctuation">(</span>
    name <span class="token operator">=</span> <span class="token string">'Product_manager'</span><span class="token punctuation">,</span>
    llm_config <span class="token operator">=</span> llm_config<span class="token punctuation">,</span>
    system_message <span class="token operator">=</span> <span class="token string">'Creative in software product ideas.'</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

groupchat <span class="token operator">=</span> autogen<span class="token punctuation">.</span>GroupChat<span class="token punctuation">(</span>agents <span class="token operator">=</span> <span class="token punctuation">[</span>user_proxy<span class="token punctuation">,</span> coder<span class="token punctuation">,</span> pm<span class="token punctuation">]</span><span class="token punctuation">,</span> messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> max_round <span class="token operator">=</span> <span class="token number">12</span><span class="token punctuation">)</span>
manager <span class="token operator">=</span> autogen<span class="token punctuation">.</span>GroupChatManager<span class="token punctuation">(</span>groupchat <span class="token operator">=</span> groupchat<span class="token punctuation">,</span> llm_config <span class="token operator">=</span> llm_config<span class="token punctuation">)</span>

result <span class="token operator">=</span> user_proxy<span class="token punctuation">.</span>initiate_chat<span class="token punctuation">(</span>
    manager<span class="token punctuation">,</span> message <span class="token operator">=</span> <span class="token string">'Discuss product design and technicalities for adding OTP based authentication in a app.'</span>
<span class="token punctuation">)</span>

<span class="token keyword">for</span> discussion <span class="token keyword">in</span> result<span class="token punctuation">.</span>chat_history<span class="token punctuation">:</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>discussion<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>discussion<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">except</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>discussion<span class="token punctuation">[</span><span class="token string">'role'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>discussion<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre></div><p>这里AssistantAgent都用到了llm，UserProxyAgent负责接收人类的输入，或者设置为允许人类输入的模式</p> <h2 id="crewai"><a href="#crewai" class="header-anchor">#</a> CrewAI</h2> <p>尽管AutoGen非常流行，但是我个人觉得CrewAI更加简单易用。请看下面的案例：
<code>pip install creai</code></p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> os
<span class="token keyword">from</span> creai <span class="token keyword">import</span> Agent<span class="token punctuation">,</span> Task<span class="token punctuation">,</span> Crew<span class="token punctuation">,</span> Process
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> HuggingFaceHub

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HUGGINGFACEHUB_API_TOKENS'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
llm <span class="token operator">=</span> HuggingFaceHub<span class="token punctuation">(</span>repo_id <span class="token operator">=</span> <span class="token string">'gemma-2b-it'</span><span class="token punctuation">,</span> model_kwargs <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">&quot;max_new_tokens&quot;</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

researcher <span class="token operator">=</span> Agent<span class="token punctuation">(</span>
    role <span class="token operator">=</span> <span class="token string">&quot;Senior Research Analyst&quot;</span><span class="token punctuation">,</span>
    goal <span class="token operator">=</span> <span class="token string">&quot;Uncover cutting-edge development in AI and data science&quot;</span><span class="token punctuation">,</span>
    backstory <span class="token operator">=</span> <span class="token string">&quot;You work at a leading tech think tank......&quot;</span><span class="token punctuation">,</span>
    verbose <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    allow_delegation <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    llm <span class="token operator">=</span> llm
<span class="token punctuation">)</span>

writer <span class="token operator">=</span> Agent<span class="token punctuation">(</span>
    role <span class="token operator">=</span> <span class="token string">&quot;Tech Content Strategist&quot;</span><span class="token punctuation">,</span>
    goal <span class="token operator">=</span> <span class="token string">&quot;......&quot;</span><span class="token punctuation">,</span>
    backstory <span class="token operator">=</span> <span class="token string">&quot;......&quot;</span><span class="token punctuation">,</span>
    verbose <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    allow_delegation <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    llm <span class="token operator">=</span> llm
<span class="token punctuation">)</span>
<span class="token comment"># Create tasks for your agents</span>
task1 <span class="token operator">=</span> Task<span class="token punctuation">(</span>
    description <span class="token operator">=</span> <span class="token string">'List down major ML algorithms.'</span><span class="token punctuation">,</span>
    expected_output <span class="token operator">=</span> <span class="token string">'Full analysis report in short bullet points.'</span><span class="token punctuation">,</span>
    agent <span class="token operator">=</span> researcher
<span class="token punctuation">)</span>

task2 <span class="token operator">=</span> Task<span class="token punctuation">(</span>
    description <span class="token operator">=</span> <span class="token string">'Using the insights provided, develop an engaging blog post that highlights the most ignificantML algorithms and a starting point for beginners. Dont use jargons'</span><span class="token punctuation">,</span>
    expected_output <span class="token operator">=</span> <span class="token string">'Full blog post of at least 4 paragraphs.'</span><span class="token punctuation">,</span>
    agent <span class="token operator">=</span> writer
<span class="token punctuation">)</span>

<span class="token comment"># Initiate your crew with a sequential process</span>
crew <span class="token operator">=</span> Crew<span class="token punctuation">(</span>
    agents <span class="token operator">=</span> <span class="token punctuation">[</span>researcher<span class="token punctuation">,</span>writer<span class="token punctuation">]</span><span class="token punctuation">,</span>
    tasks <span class="token operator">=</span> <span class="token punctuation">[</span>task1<span class="token punctuation">,</span>task2<span class="token punctuation">]</span><span class="token punctuation">,</span>
    verbose <span class="token operator">=</span> <span class="token number">2</span>
<span class="token punctuation">)</span>
<span class="token comment"># Get your crew work!</span>
res <span class="token operator">=</span> crew<span class="token punctuation">.</span>kickoff<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><h2 id="langgraph"><a href="#langgraph" class="header-anchor">#</a> LangGraph</h2> <p>LangGraph是著名的LangChain的扩展包，比AutoGen和CreAI都要复杂一些，相比于其他两个框架用起来也更加的灵活和易于定制化。LangGraph不仅可以用于MAO，也可以灵活用于其他的LMM应用。
<code>pip install langgraph</code>
在真正使用LangGraph之前，我们需要理解langchain中chain和agent的概念：</p> <ul><li>chain：LLM设计的一系列流程，原始的LangChain基于固定的流程，太过僵硬</li> <li>agent：llm+tools</li></ul> <p>LangGraph就是一种更加灵活的Chains，可以灵活引入循环、定制的逻辑</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> typing <span class="token keyword">import</span> Dict<span class="token punctuation">,</span> TypedDict<span class="token punctuation">,</span> Optional
<span class="token keyword">from</span> langgraph<span class="token punctuation">.</span>graph <span class="token keyword">import</span> StateGraph<span class="token punctuation">,</span> END
<span class="token keyword">import</span> os
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> HuggingFaceHub
os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HUGGINGFACEHUG_API_TOEKN'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span>
llm <span class="token operator">=</span> HuggingFaceHub<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>

<span class="token comment"># 初始化后续节点需要读取的信息</span>
<span class="token keyword">class</span> <span class="token class-name">StateGraph</span><span class="token punctuation">(</span>TypedDict<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 初始化后续需要用到的变量</span>
    question <span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
    classification <span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
    response <span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token comment"># 定义节点</span>
<span class="token comment"># 连接节点</span>
<span class="token comment"># 定义条件边</span>
<span class="token comment"># 执行工作流</span>
</code></pre></div></div></section> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev"><a href="/./LLM基础/使用ollama快速部署LLM.html" class="prev">
          使用ollama快速部署LLM
        </a></span> <!----></p></div> <div class="comments-wrapper"><!----></div></main></div> <!----></div> <ul class="sub-sidebar sub-sidebar-wrapper" style="width:0;" data-v-b57cc07c data-v-7dd95ae2></ul></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="./assets/js/app.427a5c72.js" defer></script><script src="./assets/js/7.7c04b33d.js" defer></script><script src="./assets/js/2.fc98b07a.js" defer></script><script src="./assets/js/1.227b7bc4.js" defer></script><script src="./assets/js/42.3b5222cb.js" defer></script>
  </body>
</html>
